package main

import (
	log "github.com/sirupsen/logrus"
	"time"
)

// A configuration for running MIDA
type MIDAConfig struct {
	// Number of simultaneous browser instances
	NumCrawlers int

	// If true, TaskLocation is an address for an AMPQ server, and credentials
	// must also be provided (as part of the URI). If false, TaskLocation
	// will be the path to the JSON file we will use to crawl (autogenerated: "MIDA_task.json")
	UseAMPQForTasks bool
	TaskLocation    string

	// Monitoring parameters
	EnableMonitoring bool
	PrometheusPort   int
}

func main() {

	mConfig := MIDAConfig{
		NumCrawlers:      DefaultNumWorkers,
		UseAMPQForTasks:  false,
		TaskLocation:     DefaultTaskLocation,
		EnableMonitoring: true,
		PrometheusPort:   DefaultPrometheusPort,
	}

	log.Info(mConfig)

	// Create channels for the pipeline
	monitoringChan := make(chan TaskStats)
	finalResultChan := make(chan FinalMIDAResult)
	rawResultChan := make(chan RawMIDAResult)
	sanitizedTaskChan := make(chan SanitizedMIDATask)
	rawTaskChan := make(chan RawMIDATask)

	// Start goroutine that runs the Prometheus monitoring HTTP server
	if mConfig.EnableMonitoring {
		go RunPrometheusClient(monitoringChan, mConfig.PrometheusPort)
	}

	// Start goroutine that handles crawl results storage
	go StoreResults(finalResultChan, mConfig)

	// Start goroutine that handles crawl results sanitization
	go ValidateResult(rawResultChan, finalResultChan)

	// Start crawler(s) which take sanitized tasks as arguments
	go CrawlerInstance(sanitizedTaskChan, rawResultChan, mConfig)

	// Start goroutine which sanitizes input tasks
	go SanitizeTasks(rawTaskChan, sanitizedTaskChan, mConfig)

	sampleTask, err := ReadTaskFromFile("examples/exampleTask.json")
	if err != nil {
		log.Fatal(err)
	}

	rawTaskChan <- sampleTask

	time.Sleep(60 * time.Second)

	// Wait on workgroup to complete

	return

}
